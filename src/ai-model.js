// src/ai-model.js
import { pipeline, env } from '@xenova/transformers';

// Configuration pour utiliser les mod√®les locaux
env.allowLocalModels = true;
env.localModelPath = './src/'; // Indique o√π chercher les mod√®les

class CustomAIModel {
  // Le nom du mod√®le que vous voulez utiliser.
  // Remplacez 'Xenova/all-MiniLM-L6-v2' par 'model.safetensors' si vous
  // avez un mod√®le compatible de ce nom dans le dossier /src.
  static modelName = 'Xenova/all-MiniLM-L6-v2';
  static instance = null;

  // Cr√©e une instance unique du pipeline (singleton)
  static async getInstance() {
    if (this.instance === null) {
      console.log('ü§ñ Chargement du mod√®le IA...');
      // Cr√©e un pipeline "feature-extraction" qui convertit le texte en vecteurs
      this.instance = await pipeline('feature-extraction', this.modelName, {
        progress_callback: (progress) => {
          console.log(`Chargement: ${progress.file} (${Math.round(progress.progress)}%)`);
        }
      });
      console.log('‚úÖ Mod√®le IA pr√™t.');
    }
    return this.instance;
  }

  // M√©thode pour utiliser le mod√®le
  async process(input) {
    try {
      const extractor = await CustomAIModel.getInstance();
      
      console.log('üß† Traitement du texte :', input);
      
      // Utilisation du mod√®le pour extraire les caract√©ristiques du texte
      const result = await extractor(input, { pooling: 'mean', normalize: true });

      // On retourne un r√©sultat simplifi√©
      return {
        succes: true,
        entree: input,
        // Les "embeddings" sont des donn√©es complexes, on montre un aper√ßu
        sortie: `Vecteur de caract√©ristiques (taille: ${result.data.length})`,
        vecteur: Array.from(result.data).slice(0, 5) // Affiche les 5 premi√®res valeurs
      };
    } catch (error) {
      console.error("‚ùå Erreur lors du traitement par l'IA :", error.message);
      throw new Error("Impossible d'ex√©cuter le mod√®le d'IA.");
    }
  }
}

export default CustomAIModel;
